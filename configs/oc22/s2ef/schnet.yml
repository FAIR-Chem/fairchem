includes:
  - configs/oc22/s2ef/base.yml

model:
  name: schnet
  hidden_channels: 1024
  num_filters: 256
  num_interactions: 5
  num_gaussians: 200
  cutoff: 6.0
  use_pbc: True
  otf_graph: True

optim:
  batch_size: 20
  eval_batch_size: 20
  eval_every: 5000
  num_workers: 8
  lr_initial: 0.00025
  warmup_steps: -1 # don't warm-up the learning rate
  # warmup_factor: 0.2
  lr_gamma: 0.8
  # Following calculation is for an effective batch size of 20 x 16 GPUs = 320
  # and a dataset size of 8225293 (1 epoch ~ 26000 steps).
  lr_milestones: # steps at which lr_initial <- lr_initial * lr_gamma
    - 52000 # ~2 epochs
    - 77000 # ~3 epochs
    - 103000 # ~4 epochs
    - 129000 # ~5 epochs
    - 154000 # ~6 epochs
  max_epochs: 80
