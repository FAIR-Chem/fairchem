includes:
  - configs/atat/transformer_ablation/base.yml

model:
  name: sparse_transformer
  elements: [1, 6, 7, 8]
  embed_dim: 256
  hidden_dim: 256
  dropout: 0.
  num_layers: 12
  num_heads: 16
  otf_graph: True
  rbf_radius: 6.
  num_gaussians: 64
  num_pair_embed_layers: 2
  use_vec_hat: True
  output_layers: 4
  avg_atoms: 60

optim:
  batch_size: 32
  eval_batch_size: 32
  load_balancing: atoms
  num_workers: 16
  lr_initial: 0.0004

  optimizer: AdamW
  optimizer_params:
    weight_decay: 0.001
  scheduler: ReduceLROnPlateau
  mode: min
  factor: 0.9
  patience: 100
  max_epochs: 10000
  force_coefficient: 10
  energy_coefficient: 1
  ema_decay: 0.999
  clip_grad_norm: 10
  loss_energy: mae
  loss_force: l2mae
