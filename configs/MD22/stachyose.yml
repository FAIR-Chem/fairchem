trainer: forces

dataset:
  train:
    src: /data/ericqu/md22/lmdb/stachyose/train/
    normalize_labels: True
    target_mean: -68463.59
    target_std: 0.5940788
    grad_target_mean: 0.0
    grad_target_std: 1.1104717
  val: 
    src: /data/ericqu/md22/lmdb/stachyose/val/
  test:
    src: /data/ericqu/md22/lmdb/stachyose/test/

logger: 
  name: wandb
  project: MD22

task:
  dataset: trajectory_lmdb
  description: "Regressing to energies and forces for DFT trajectories from MD22"
  type: regression
  metric: mae
  labels:
    - potential energy
  grad_input: atomic forces
  train_on_free_atoms: True
  eval_on_free_atoms: True

model:
  name: transformer
  num_elements: 100
  embed_dim: 256
  hidden_dim: 256
  dropout: 0.
  num_layers: 8
  num_heads: 16
  otf_graph: True
  rbf_radius: 15.
  num_gaussians: 64
  trainable_rbf: False
  num_pair_embed_layers: 2
  pair_embed_style: shared
  gate_pair_embed: True
  output_layers: 4
  gate_output: False
  avg_atoms: 60
  pos_emb_style: naive
  pos_scale: 6

optim:
  batch_size: 32
  eval_batch_size: 32
  load_balancing: atoms
  num_workers: 16
  lr_initial: 0.0004
  optimizer: AdamW
  optimizer_params:
    weight_decay: 0.001
  scheduler: ReduceLROnPlateau
  mode: min
  factor: 0.95
  patience: 100
  max_epochs: 10000
  force_coefficient: 10
  energy_coefficient: 1
  ema_decay: 0.999
  clip_grad_norm: 10
  loss_energy: mae
  loss_force: l2mae
