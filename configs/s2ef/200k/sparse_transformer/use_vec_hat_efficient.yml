includes:
  - configs/s2ef/200k/base.yml

model:
  name: sparse_transformer
  elements: [
    1,  5,  6,  7,  8, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25,
    26, 27, 28, 29, 30, 31, 32, 33, 34, 37, 38, 39, 40, 41, 42, 43, 44, 45,
    46, 47, 48, 49, 50, 51, 52, 55, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,
    82, 83
  ]
  embed_dim: 512
  hidden_dim: 512
  dropout: 0.
  num_layers: 12
  num_heads: 16
  otf_graph: True
  use_pbc: True
  rbf_radius: 6.
  num_gaussians: 64
  pair_embed_style: efficient
  use_vec_hat: True
  output_layers: 4
  avg_atoms: 60

optim:
  batch_size: 8
  eval_batch_size: 8
  load_balancing: atoms
  num_workers: 8
  lr_initial: 0.0004

  optimizer: AdamW
  optimizer_params:
    weight_decay: 0.001
  scheduler: ReduceLROnPlateau
  mode: min
  factor: 0.8
  patience: 3
  max_epochs: 80
  force_coefficient: 100
  energy_coefficient: 1
  ema_decay: 0.999
  clip_grad_norm: 10
  loss_energy: mae
  loss_force: l2mae
