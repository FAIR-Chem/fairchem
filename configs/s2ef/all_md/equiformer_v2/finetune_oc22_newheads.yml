dataset:
  train:
    src: /large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/train_ef/
    metadata_path: /checkpoint/bmwood/nima_checkpoints/oc22_metadata/oc22_metadata/train_metadata.npz
    key_mapping:
      y: energy
      force: forces
  val:
    src: /large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/val_id_30k/
    metadata_path: /large_experiments/opencatalyst/data/oc22/2022_06_16/s2ef/val_id_30k/metadata.npz
    sample_n: 10
  dataset_name: oc22
  format: mt_lmdb
  transforms:
    oc22_transform:
      dataset_name: oc22
    normalizer:
      energy:
        mean: 0.0
        stdev: 25.229595396538468
      forces:
        mean: 0.0
        stdev: 0.25678861141204834
    element_references:
      energy:
        file: /private/home/bmwood/ocp_results/fm_ocp/ocp/configs/oc22/linref/oc22_linfit_coeffs.npz

trainer: forces

model:
  name: finetune_hydra
  finetune_config:
    mode: RETAIN_BACKBONE_ONLY
    starting_checkpoint: "./checkpoints/2024-08-09-06-19-44-fc_main_allmd_EQV231Mhydra/checkpoint.pt"
    heads:
      energy:
        module: equiformer_v2_energy_head
      forces:
        module: equiformer_v2_force_head

logger: 
  name: wandb
  project: fm_testing
  entity: fairchem

optim:
  batch_size: 8
  eval_batch_size: 8
  load_balancing: atoms
  num_workers: 8
  optimizer: AdamW
  optimizer_params:
    amsgrad: True
    weight_decay: 0  # 2e-6 (TF weight decay) / 1e-4 (lr) = 2e-2
  lr_initial: 1.e-4
  scheduler: ReduceLROnPlateau
  mode: min
  factor: 0.8
  patience: 3
  max_epochs: 80
  ema_decay: 0.999
  clip_grad_norm: 10

outputs:
  energy:
    shape: 1
    level: system
  forces:
    irrep_dim: 1
    level: atom
    train_on_free_atoms: True
    eval_on_free_atoms: True

loss_functions:
  - energy:
      fn: mae
      coefficient: 2
  - forces:
      fn: l2mae
      coefficient: 100

evaluation_metrics:
  metrics:
    energy:
      - mae
    forces:
      - mae
      - cosine_similarity
      - magnitude_error
    misc:
      - energy_forces_within_threshold
  primary_metric: forces_mae

slurm:
  constraint: "volta32gb"