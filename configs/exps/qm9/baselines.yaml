# more epochs, larger batch size, explore fanet: larger model & skip-co & mlp_rij
job:
  mem: 48GB
  cpus: 6
  gres: gpu:1
  time: 12:00:00
  partition: long
  code_loc: /home/mila/s/schmidtv/ocp-project/run-repos/ocp-2

default:
  wandb_project: ocp-qm9
  mode: train
  test_ri: true
  wandb_tags: qm9-baselines
  phys_hidden_channels: 0
  phys_embeds: False
  energy_head: False
  pg_hidden_channels: 0
  tag_hidden_channels: 0

runs:
  - config: dpp-qm9-all
    note: DimeNet++ qm9 baseline
    # https://github.com/gasteigerjo/dimenet/blob/fd36d381a2b31721da0cbf879b2d0c0a166fa76b/config.yaml

    # TODO: num GPUs/batch_size, epochs, lr decay, emb_size, num_dense_output
    model:
      cutoff: 5.0
      num_before_skip: 1
      num_after_skip: 2
      num_blocks: 6
      int_emb_size: 128
    optim:
      lr_initial: 0.001
      warmup_steps: 3000
      batch_size: 32
      max_epochs: 100

  - config: schnet-qm9-all
    note: SchNet qm9 baseline