# trainset has 4068193 samples
job:
  mem: 32GB
  cpus: 4
  gres: gpu:1
  time: "12:00:00"

default:
  wandb_project: ocp-qm
  mode: train
  test_ri: true
  wandb_tags: qm9
  cp_data_to_tmpdir: true
  note:
    task: name
    model: name, num_gaussians, hidden_channels, num_filters, num_interactions, regress_forces
    optim: batch_size, lr_initial, energy_coefficient, force_coefficient, energy_grad_coefficient
  log_train_every: 250
  energy_head: False
  frame_averaging: ""
  fa_frames: ""
  optim:
    batch_size: 100
    max_steps: 2000000
    warmup_steps: 3000
    lr_initial: 0.00025
    eval_every: 1
    energy_coefficient: 1
    energy_grad_coefficient: 0
    force_coefficient: 100
    # parameters EMA
    ema_decay: 0.999
    loss_energy: mae
    loss_force: mse
    # all below is for the scheduler
    scheduler: ReduceLROnPlateau
    mode: min
    factor: 0.75
    threshold: 0.001
    threshold_mode: abs
    min_lr: 0.000001
    verbose: true
  dataset:
    train:
      rescale_with_hof: False
      lse_shift: True
    val_id:
      lse_shift: True
    test:
      lse_shift: True

runs:
  - config: dpp-qm9-all
    model:
      cutoff: 5
      num_spherical: 7
      num_radial: 6
      envelope_exponent: 5
      num_before_skip: 1
      num_after_skip: 2
      num_dense_output: 3
    optim:
      batch_size: 32
      lr_initial: 0.001
      warmup_steps: 3000

  - config: schnet-qm9-all
    model:
      cutoff: 5
      hidden_channels: 128
      max_num_neighbors: 40
      num_filters: 128
      num_gaussians: 100
      num_interactions: 6
      pg_hidden_channels: 0
      phys_embeds: false