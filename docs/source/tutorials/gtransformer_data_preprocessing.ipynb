{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "natural-debut",
   "metadata": {},
   "source": [
    "### OCP Data Preprocessing Tutorial\n",
    "\n",
    "\n",
    "This notebook provides an overview of converting ASE Atoms objects to PyTorch Geometric Data objects. To better understand the raw data contained within OC20, check out the following tutorial first: https://github.com/Open-Catalyst-Project/ocp/blob/master/docs/source/tutorials/data_playground.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ocpmodels.preprocessing import AtomsToGraphs\n",
    "import ase.io\n",
    "from ase.build import bulk\n",
    "from ase.build import fcc100, add_adsorbate, molecule\n",
    "from ase.constraints import FixAtoms\n",
    "from ase.calculators.emt import EMT\n",
    "from ase.optimize import BFGS\n",
    "import torch\n",
    "from torch_geometric.data import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "august-meaning",
   "metadata": {},
   "source": [
    "### Generate toy dataset: Relaxation of CO on Cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-swiss",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "adslab = fcc100(\"Cu\", size=(2, 2, 3))\n",
    "ads = molecule(\"CO\")\n",
    "add_adsorbate(adslab, ads, 3, offset=(1, 1))\n",
    "cons = FixAtoms(indices=[atom.index for atom in adslab if (atom.tag == 3)])\n",
    "adslab.set_constraint(cons)\n",
    "adslab.center(vacuum=13.0, axis=2)\n",
    "adslab.set_pbc(True)\n",
    "adslab.set_calculator(EMT())\n",
    "dyn = BFGS(adslab, trajectory=\"CuCO_adslab.traj\", logfile=None)\n",
    "dyn.run(fmax=0, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-stuff",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "raw_data = ase.io.read(\"CuCO_adslab.traj\", \":\")\n",
    "print(len(raw_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-joseph",
   "metadata": {},
   "source": [
    "### Convert Atoms object to Data object\n",
    "\n",
    "The AtomsToGraphs class takes in several arguments to control how Data objects created:\n",
    "\n",
    "- max_neigh (int):   Maximum number of neighbors a given atom is allowed to have, discarding the furthest\n",
    "- radius (float):      Cutoff radius to compute nearest neighbors around\n",
    "- r_energy (bool):    Write energy to Data object\n",
    "- r_forces (bool):    Write forces to Data object\n",
    "- r_distances (bool): Write distances between neighbors to Data object\n",
    "- r_edges (bool):     Write neigbhor edge indices to Data object\n",
    "- r_fixed (bool):     Write indices of fixed atoms to Data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-bunch",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "a2g = AtomsToGraphs(\n",
    "    max_neigh=50,\n",
    "    radius=6,\n",
    "    r_energy=True,\n",
    "    r_forces=True,\n",
    "    r_distances=False,\n",
    "    r_edges=True,\n",
    "    r_fixed=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-headset",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_objects = a2g.convert_all(raw_data, disable_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-future",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data = data_objects[0]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "ignored-offering",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([29., 29., 29., 29., 29., 29., 29., 29., 29., 29., 29., 29.,  8.,  6.])"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.atomic_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "conventional-liability",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.1053,  0.0000,  0.0000],\n",
       "         [ 0.0000,  5.1053,  0.0000],\n",
       "         [ 0.0000,  0.0000, 32.6100]]])"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "ruled-fundamental",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5,  7,  6,  ...,  4,  6,  7],\n",
       "        [ 0,  0,  0,  ..., 13, 13, 13]])"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_index #neighbor idx, source idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "cooperative-warehouse",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "satisfactory-petroleum",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.2306e-15,  1.4246e-16, -1.6429e-02],\n",
       "        [ 2.2372e-15,  1.8440e-15, -6.4668e-04],\n",
       "        [ 2.5206e-15,  5.8791e-15, -6.4668e-04],\n",
       "        [-1.8058e-15, -4.0592e-15,  1.7722e-02],\n",
       "        [ 1.2381e-14,  2.5091e-15, -1.3239e-15],\n",
       "        [-1.2242e-14, -1.0446e-14,  3.2344e-15],\n",
       "        [-3.1921e-15,  4.7090e-15,  6.3805e-15],\n",
       "        [ 5.3794e-15, -3.5640e-15,  5.0293e-15],\n",
       "        [ 5.6747e-15, -2.7279e-16, -6.8647e-15],\n",
       "        [-2.9879e-15, -1.2906e-15, -6.5919e-15],\n",
       "        [ 3.8997e-15,  7.8866e-15,  1.3808e-15],\n",
       "        [-6.4576e-15, -4.2618e-15,  1.1362e-14],\n",
       "        [ 4.6960e-18, -1.0266e-17, -4.7148e-14],\n",
       "        [-1.3401e-16,  2.1034e-16,  3.8341e-14]])"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "broad-rouge",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  1.3000e+01],\n",
       "        [ 2.5527e+00,  0.0000e+00,  1.3000e+01],\n",
       "        [ 0.0000e+00,  2.5527e+00,  1.3000e+01],\n",
       "        [ 2.5527e+00,  2.5527e+00,  1.3000e+01],\n",
       "        [ 1.2741e+00,  1.2741e+00,  1.4778e+01],\n",
       "        [ 3.8312e+00,  1.2741e+00,  1.4778e+01],\n",
       "        [ 1.2741e+00,  3.8312e+00,  1.4778e+01],\n",
       "        [ 3.8312e+00,  3.8312e+00,  1.4778e+01],\n",
       "        [-7.6910e-16, -1.9714e-15,  1.6562e+01],\n",
       "        [ 2.5527e+00, -1.3052e-15,  1.6567e+01],\n",
       "        [ 1.2551e-15,  2.5527e+00,  1.6567e+01],\n",
       "        [ 2.5527e+00,  2.5527e+00,  1.6539e+01],\n",
       "        [ 2.5527e+00,  2.5527e+00,  1.9567e+01],\n",
       "        [ 2.5527e+00,  2.5527e+00,  1.8443e+01]])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "coupled-orchestra",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.968355893395698"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-treat",
   "metadata": {},
   "source": [
    "### Adding additional info to your Data objects\n",
    "\n",
    "In addition to the above information, the OCP repo requires several other pieces of information for your data to work\n",
    "with the provided trainers:\n",
    "\n",
    "- sid (int): A unique identifier for a particular system. Does not affect your model performance, used for prediction saving \n",
    "- fid (int) (S2EF only): If training for the S2EF task, your data must also contain a unique frame identifier for atoms objects coming from the same system.\n",
    "- tags (tensor): Tag information - 0 for adsorbate, 1 for surface, 2 for subsurface. Optional, can be used for training.\n",
    "\n",
    "\n",
    "Other information may be added her as well if you choose to incorporate other information in your models/frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "simple-champion",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "data_objects = []\n",
    "for idx, system in enumerate(raw_data):\n",
    "    data = a2g.convert(system)\n",
    "    data.fid = idx\n",
    "    data.sid = 0 # All data points come from the same system, arbitrarly define this as 0\n",
    "    data_objects.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "subjective-present",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(atomic_numbers=[14], cell=[1, 3, 3], cell_offsets=[635, 3], edge_index=[2, 635], fid=100, fixed=[14], force=[14, 3], natoms=14, pos=[14, 3], sid=0, y=3.968355893395698)"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_objects[100]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "thick-geology",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "elegant-amendment",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "civil-better",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Helper function to convert from PyTorch Geometric input to GROVER input:\n",
    "def convert_input(data):\n",
    "    \"\"\"\n",
    "        :param data: data as PyTorch geometric object\n",
    "        :param f_atoms: the atom features, num_atoms * atom_dim\n",
    "        :param f_bonds: the bond features, num_bonds * bond_dim\n",
    "        :param a2b: mapping from atom index to incoming bond indices. \n",
    "        :param a2a: mapping from atom index to its neighbors. num_atoms * max_num_bonds\n",
    "        :param b2a: mapping from bond index to the index of the atom the bond is coming from.\n",
    "        :param b2revb: mapping from bond index to the index of the reverse bond.\n",
    "        :return: batch = (f_atoms, f_bonds, a2b, a2a, b2a, b2revb)\n",
    "    \"\"\"\n",
    "    # Per atom features: (atomic_number, pos_x, pos_y, pos_z)\n",
    "    f_atoms = torch.stack((data.atomic_numbers.long(), data.pos[:,0], data.pos[:,1], data.pos[:,2]), 1)\n",
    "    # Per edge features (calculated by atomic distances in model forward pass)\n",
    "    f_bonds = data.edge_attr\n",
    "\n",
    "    a2a = [[] for j in range(data.natoms)] # List of lists - Dynamically append neighbors for a given atom\n",
    "    a2b = [[] for j in range(data.natoms)] # List of lists - Dynamically append edges for a given atom\n",
    "    b2a = torch.zeros((data.edge_index.shape[1],))  # (num_edges, ) - One originating atom per edge\n",
    "    b2revb = torch.zeros((data.edge_index.shape[1],))  # (num_edges, ) - One reverse bond per bond\n",
    "    rev_edges = {} # Dict of lists for each (from_atom, to_atom) pair, saving edge numbers\n",
    "\n",
    "    # Loop through every edge in the graph\n",
    "    for i in range(data.edge_index.shape[1]):\n",
    "        from_atom = int(data.edge_index[0][i])\n",
    "        to_atom = int(data.edge_index[1][i])\n",
    "\n",
    "        a2a[from_atom].append(to_atom)  # Mark b as neighbor of a\n",
    "        a2b[to_atom].append(i)  # Mark bond i as incoming bond to atom a\n",
    "        b2a[i] = from_atom  # Mark a as atom where bond i is originating\n",
    "        key = frozenset({to_atom, from_atom})\n",
    "        if (key not in rev_edges):  # If the edge from these two atoms has not been seen yet\n",
    "            rev_edges[key] = []  # Declare it as a list (so we can keep track of the edge numbers)\n",
    "        rev_edges[key].append(i)  # Append the edge number to the list\n",
    "\n",
    "    # Iterate through and set b2revb\n",
    "    for atoms, edges in rev_edges.items():\n",
    "        b2revb[edges[0]] = edges[1]\n",
    "        b2revb[edges[1]] = edges[0]\n",
    "\n",
    "\n",
    "      # Convert list of lists for a2a and a2b into tensor: (num_nodes, max_edges)\n",
    "    # Trim length to max number of edges seen in the data (should be capped by 50 but not always in practice)\n",
    "    a2a_pad = len(max(a2a, key=len))\n",
    "    a2b_pad = len(max(a2b, key=len))\n",
    "\n",
    "    # -1 is not a valid atom or edge index so we pad with this\n",
    "    a2a = torch.tensor([i + [0] * (a2a_pad - len(i)) for i in a2a])\n",
    "    a2b = torch.tensor([i + [0] * (a2b_pad - len(i)) for i in a2b])\n",
    "\n",
    "    batch = (f_atoms, f_bonds, a2b, a2a, b2a, b2revb)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "simplified-replacement",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5,  7,  6,  ...,  4,  6,  7],\n",
      "        [ 0,  0,  0,  ..., 13, 13, 13]])\n",
      "tensor([[ 5,  0],\n",
      "        [ 7,  0],\n",
      "        [ 6,  0],\n",
      "        ...,\n",
      "        [ 4, 13],\n",
      "        [ 6, 13],\n",
      "        [ 7, 13]])\n",
      "tensor([[ 0,  7],\n",
      "        [ 0,  2],\n",
      "        [ 0,  2],\n",
      "        ...,\n",
      "        [13,  3],\n",
      "        [13, 11],\n",
      "        [13,  6]])\n",
      "tensor([[ 0,  0,  0,  ..., 13, 13, 13],\n",
      "        [ 7,  2,  2,  ...,  3, 11,  6]])\n",
      "out:  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])\n",
      "out:  tensor([ 0,  1,  2,  4,  5,  6,  7,  9, 10, 11, 12, 13])\n",
      "counts:  tensor([45, 45, 45, 46, 48, 49, 49, 50, 53, 46, 47, 55, 22, 35])\n",
      "counts:  tensor([45, 45, 45, 48, 49, 49, 50, 46, 47, 55, 22, 35])\n",
      "ascending:  tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13])\n",
      "missing:  [False, False, False, True, False, False, False, False, True, False, False, False, False, False]\n",
      "np.nonzero:  [3 8]\n",
      "i:  3\n",
      "counts:  tensor([45, 45, 45, 48, 49, 49, 50, 46, 47, 55, 22, 35])\n",
      "counts:  tensor([45, 45, 45,  0, 48, 49, 49, 50, 46, 47, 55, 22, 35])\n",
      "i:  8\n",
      "counts:  tensor([45, 45, 45,  0, 48, 49, 49, 50, 46, 47, 55, 22, 35])\n",
      "counts:  tensor([45, 45, 45,  0, 48, 49, 49, 50,  0, 46, 47, 55, 22, 35])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "split_with_sizes expects split_sizes to sum exactly to 635 (input tensor's size at dimension 0), but got split_sizes=[45, 45, 45, 0, 48, 49, 49, 50, 0, 46, 47, 55, 22, 35]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-519-847175d7c40b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0mcounts\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcounts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcounts\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mi\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;31m# Add zero to count\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     40\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"counts: \"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcounts\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 41\u001B[0;31m \u001B[0ma2a2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msorted_index\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcounts\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# Index into to_bonds with these indices\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     42\u001B[0m \u001B[0ma2a2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad_sequence\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ma2a2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatch_first\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpadding_value\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/ocp-models/lib/python3.6/site-packages/torch/tensor.py\u001B[0m in \u001B[0;36msplit\u001B[0;34m(self, split_size, dim)\u001B[0m\n\u001B[1;32m    474\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit_with_sizes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msplit_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    475\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 476\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit_with_sizes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msplit_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    477\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    478\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0munique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msorted\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_inverse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_counts\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: split_with_sizes expects split_sizes to sum exactly to 635 (input tensor's size at dimension 0), but got split_sizes=[45, 45, 45, 0, 48, 49, 49, 50, 0, 46, 47, 55, 22, 35]"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import degree\n",
    "# print(degree(data.edge_index[0]))\n",
    "# print(torch.max(degree(data.edge_index[0])))\n",
    "\n",
    "\n",
    "batch = convert_input(data)\n",
    "f_atoms, f_bonds, a2b, a2a, b2a, b2revb = batch\n",
    "\n",
    "# Calculate atom to neighboring atom mappings (a2a)\n",
    "print(data.edge_index)\n",
    "trans = data.edge_index.T\n",
    "print(trans)\n",
    "sorted_index = trans[trans[:, 0].sort()[1]]  # Sort by column zero (from_node), index based off\n",
    "print(sorted_index)\n",
    "sorted_index = sorted_index.T\n",
    "print(sorted_index)\n",
    "\n",
    "\n",
    "out, counts = torch.unique(sorted_index[0], return_counts=True)  # counts for each atom\n",
    "print(\"out: \", out)\n",
    "out = torch.cat((out[:3], out[4:]))\n",
    "out = torch.cat((out[:7], out[8:]))\n",
    "print(\"out: \", out)\n",
    "print(\"counts: \", counts)\n",
    "counts = torch.cat((counts[:3], counts[4:]))\n",
    "counts = torch.cat((counts[:7], counts[8:]))\n",
    "print(\"counts: \", counts)\n",
    "\n",
    "if len(out) - 1 != out[-1]: # If they are the correct length then we don't need to add 0's\n",
    "    ascending = torch.arange(out[-1] + 1) # Ascending order list [0, 1, ... n] where n is last elem in out\n",
    "    print(\"ascending: \", ascending)\n",
    "    missing = [ elem not in out for elem in ascending ] # Missing elements in out\n",
    "    print(\"missing: \", missing)\n",
    "    print(\"np.nonzero: \", np.nonzero(missing)[0])\n",
    "    for elem in np.nonzero(missing)[0]:\n",
    "        i = int(elem)\n",
    "        print(\"i: \", i)\n",
    "        print(\"counts: \", counts)\n",
    "        counts = torch.cat((counts[:i], torch.tensor((0,)), counts[i:])) # Add zero to count\n",
    "        print(\"counts: \", counts)\n",
    "        \n",
    "a2a2 = sorted_index[1].split(counts.tolist())  # Index into to_bonds with these indices\n",
    "\n",
    "a2a2 = torch.nn.utils.rnn.pad_sequence(list(a2a2), batch_first=True, padding_value=0)  \n",
    "\n",
    "print(\"a2a2.shape\", a2a2.shape)\n",
    "print(\"a2a.shape\", a2a.shape)\n",
    "print(\"a2a[0]: \", a2a[0])\n",
    "print(\"a2a2[0]: \", a2a2[0])\n",
    "print(\"\\na2a and a2a2 equal: \", torch.equal(a2a, a2a2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-synthetic",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# # Efficient b2a calculation\n",
    "# b2a2 = data.edge_index[0].type(torch.FloatTensor)\n",
    "# print(\"\\nb2a and b2a2 equal: \", torch.equal(b2a2, b2a))\n",
    "\n",
    "# # Efficient a2b calculation\n",
    "# num_atoms_total = data.natoms\n",
    "# count, idx = torch.unique(data.edge_index[1], return_counts=True)\n",
    "# max_bonds = int(torch.max(degree(data.edge_index[1])))\n",
    "\n",
    "# a2b1 = torch.zeros(num_atoms_total, max_bonds)\n",
    "# for i in range(len(idx)):\n",
    "#     if i == 0:\n",
    "#         start_index = 0\n",
    "#         indices = torch.arange(0, idx[i])\n",
    "#         a2b1[i] = torch.cat((indices, torch.zeros(len(a2b1[0]) - len(indices))), 0)\n",
    "#     else:\n",
    "#         end_index = start_index + idx[i]\n",
    "#         indices = torch.arange(start_index, end_index)\n",
    "#         a2b1[i] = torch.cat((indices, torch.zeros(len(a2b1[0]) - len(indices))), 0)\n",
    "#     start_index = start_index + idx[i]    \n",
    "# a2b1 = a2b1.type(torch.LongTensor)\n",
    "\n",
    "# print(\"\\na2b and a2b1 equal? \", torch.equal(a2b, a2b1))\n",
    "\n",
    "# TODO: efficient b2revb calculation\n",
    "\n",
    "\n",
    "\n",
    "# print(\"\\nShapes of parameters\")\n",
    "# print(\"f_atoms: \", f_atoms.shape)\n",
    "# print(\"f_bonds: \", f_bonds.shape)\n",
    "# print(\"a2b: \", a2b.shape)\n",
    "# print(\"a2a: \", a2a.shape)\n",
    "# print(\"b2a: \", b2a.shape)\n",
    "# print(\"b2revb: \", b2revb.shape)\n",
    "\n",
    "# print(\"\\nExample data\")\n",
    "# print(\"Atom features index 0: \", f_atoms[0])\n",
    "# print(\"Edge features index 0: \", f_bonds[0])\n",
    "# print(\"a2b atom 0: \", a2b[0])\n",
    "# print(\"a2a atom 0: \", a2a[0])\n",
    "# print(\"b2a edge 0: \", b2a[0])\n",
    "# print(\"b2revb edge 0: \", b2revb[0])\n",
    "\n",
    "# for atom in a2b:\n",
    "#     for bond in atom:\n",
    "#         print(dtype(bond))\n",
    "#         if(bond != torch.tensor(-1)):\n",
    "#             print(\"bond: \", bond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electrical-watch",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generate example data (3 nodes)\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "atomic_numbers = data.atomic_numbers[11:14]\n",
    "\n",
    "edge_attr = data.edge_attr[:3]\n",
    "\n",
    "pos = data.pos[:3]\n",
    "\n",
    "data2 = Data(x=x, edge_index=edge_index, atomic_numbers=atomic_numbers, edge_attr=edge_attr, natoms=3, pos=pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-failure",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "understood-copper",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch = convert_input(data2)\n",
    "f_atoms, f_bonds, a2b, a2a, b2a, b2revb = batch\n",
    "print(\"Shapes of parameters\")\n",
    "print(\"f_atoms: \", f_atoms.shape)\n",
    "print(\"f_bonds: \", f_bonds.shape)\n",
    "print(\"a2b: \", a2b.shape)\n",
    "print(\"a2a: \", a2a.shape)\n",
    "print(\"b2a: \", b2a.shape)\n",
    "print(\"b2revb: \", b2revb.shape)\n",
    "\n",
    "print(\"\\nExample data\")\n",
    "print(\"Atom features: \", f_atoms)\n",
    "print(\"Edge features: \", f_bonds)\n",
    "print(\"a2b: \", a2b)\n",
    "print(\"a2a: \", a2a)\n",
    "print(\"b2a: \", b2a)\n",
    "print(\"b2revb: \", b2revb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "derived-effort",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Resources:\n",
    "\n",
    "- https://github.com/Open-Catalyst-Project/ocp/blob/6604e7130ea41fabff93c229af2486433093e3b4/ocpmodels/preprocessing/atoms_to_graphs.py\n",
    "- https://github.com/Open-Catalyst-Project/ocp/blob/master/scripts/preprocess_ef.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-tumor",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-fancy",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}