trainer: forces

dataset:
  - src: data/s2ef/all/train/
    normalize_labels: True
    target_mean: -0.7554450631141663
    target_std: 2.887317180633545
    grad_target_mean: 0.0
    grad_target_std: 2.887317180633545
  - src: data/s2ef/all/val_id_30k/

logger: wandb

task:
  dataset: trajectory_lmdb
  primary_metric: forces_mae
  train_on_free_atoms: True
  eval_on_free_atoms: True
  eval_relaxations: True
  relaxation_steps: 300
  relaxation_fmax: 0.02
  write_pos: False
  relax_dataset:
    src: path/to/oc20-dense/dataset #TODO
  relax_opt:
    name: lbfgs
    maxstep: 0.04
    memory: 50
    damping: 1.0
    alpha: 70.0
    traj_dir: path/to/save/ml/relaxations #TODO

model:
  name: scn
  num_interactions: 16
  hidden_channels: 1024
  sphere_channels: 128
  sphere_channels_reduce: 128
  num_sphere_samples: 128
  num_basis_functions: 128
  distance_function: "gaussian"
  show_timing_info: False
  max_num_neighbors: 40
  cutoff: 8.0
  lmax: 6
  num_bands: 2
  use_grid: True
  regress_forces: True
  use_pbc: True
  basis_width_scalar: 2.0
  otf_graph: True

optim:
  batch_size: 2
  eval_batch_size: 1
  num_workers: 2
  lr_initial: 0.0004
  optimizer: AdamW
  optimizer_params: {"amsgrad": True}
  eval_every: 5000
  lr_gamma: 0.3
  lr_milestones: # epochs at which lr_initial <- lr_initial * lr_gamma
    - 260000
    - 340000
    - 420000
    - 500000
    - 800000
    - 1000000
  warmup_steps: 100
  warmup_factor: 0.2
  max_epochs: 12
  force_coefficient: 100
  energy_coefficient: 4
  clip_grad_norm: 100
  ema_decay: 0.999
  loss_energy: mae
  loss_force: l2mae
