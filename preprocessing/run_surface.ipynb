{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1\n",
    "%env CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "from bisect import bisect\n",
    "\n",
    "from torch_geometric.data import DataLoader, InMemoryDataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "\n",
    "# From .py's\n",
    "from models.dogss import DOGSS\n",
    "from train_positions import Trainer\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOwnDataset(InMemoryDataset):\n",
    "    def __init__(self, root, transform=None, pre_transfrom=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform=None)\n",
    "#         self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "#         print(self.processed_paths[0])\n",
    "        self.data, self.slices = torch.load('./data_surfaces.pt')\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return \"data_surfaces.pt\"\n",
    "\n",
    "    def _download(self):\n",
    "        pass\n",
    "\n",
    "    def _process(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%rm -r ./surface\n",
    "\n",
    "\n",
    "save_dir = './surface'\n",
    "if not os.path.exists('surface'):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "log_dir = './surface/log'\n",
    "if not os.path.exists('./surface/log'):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "dataset = MyOwnDataset(root='./').shuffle()    \n",
    "dataset = dataset[:500]\n",
    "\n",
    "train_size = int(len(dataset)*0.8)\n",
    "val_size = int(len(dataset)*0.1)\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "batch_size=17\n",
    "n_epoch=200\n",
    "lr_initial=0.0393415\n",
    "lr_gamma=0.1\n",
    "lr_milestones=[100, 150]\n",
    "warmup_epochs=10\n",
    "warmup_factor=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dataset) >= train_size + val_size + test_size\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "val_dataset = dataset[train_size : train_size + val_size]\n",
    "test_dataset = dataset[train_size + val_size : train_size + val_size + test_size]\n",
    "\n",
    "\n",
    "# torch.save(dataset, os.path.join(save_dir, 'dataset.pt'))\n",
    "# torch.save(train_dataset, os.path.join(save_dir, 'train_dataset.pt'))\n",
    "# torch.save(val_dataset, os.path.join(save_dir, 'val_dataset.pt'))\n",
    "# torch.save(test_dataset, os.path.join(save_dir, 'test_dataset.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "# dataset = torch.load(os.path.join(save_dir, 'dataset.pt'))\n",
    "# train_dataset = torch.load(os.path.join(save_dir, 'train_dataset.pt'))\n",
    "# val_dataset = torch.load(os.path.join(save_dir, 'val_dataset.pt'))\n",
    "# test_dataset = torch.load(os.path.join(save_dir, 'test_dataset.pt'))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, batch_size=batch_size\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class loss():\n",
    "    def distance_loss(self, pred, true):\n",
    "        pred = pred[0] if isinstance(pred, tuple) else pred \n",
    "        diff = torch.sum((pred-true)**2, dim=1)\n",
    "#         diff = torch.clamp(diff, min=1e-6)\n",
    "        return torch.mean(torch.sqrt(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import DOGSSConv\n",
    "\n",
    "\n",
    "######## \n",
    "log_writer = SummaryWriter(log_dir)\n",
    "#########\n",
    "\n",
    "conv_layer = DOGSSConv\n",
    "\n",
    "# Build model\n",
    "model = DOGSS(\n",
    "    num_atoms = dataset.data.x.shape[-1],\n",
    "    bond_feat_dim = dataset.data.edge_attr.shape[-1],\n",
    "    atom_embedding_size=236,\n",
    "    num_graph_conv_layers=12,\n",
    "    num_dist_layers=0,\n",
    "    num_const_layers =0,\n",
    "    fc_feat_size=6,\n",
    "    dist_feat_dim = 4,\n",
    "    const_feat_dim = 4,\n",
    "    D_feat_dim = 128,\n",
    "    max_num_nbr = 12,\n",
    "    energy_mode = \"Harmonic\",\n",
    "    max_opt_steps = 300,\n",
    "    min_opt_steps = 10,\n",
    "    opt_step_size = 0.3,\n",
    "    momentum = 0.8,\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "# criterion = nn.L1Loss()\n",
    "criterion = loss().distance_loss\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr = lr_initial)\n",
    "\n",
    "def lr_lambda_fun(current_epoch):\n",
    "    \"\"\"Returns a learning rate multiplier.\n",
    "    Till `warmup_epochs`, learning rate linearly increases to `initial_lr`,\n",
    "    and then gets multiplied by `lr_gamma` every time a milestone is crossed.\n",
    "    \"\"\"\n",
    "    if current_epoch <= warmup_epochs:\n",
    "        alpha = current_epoch / float(warmup_epochs)\n",
    "        return warmup_factor * (1.0 - alpha) + alpha\n",
    "    else:\n",
    "        idx = bisect(lr_milestones, current_epoch)\n",
    "        return pow(lr_gamma, idx)\n",
    "\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_lambda_fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    criterion = criterion,\n",
    "    optimizer = optimizer,\n",
    "    scheduler = scheduler,\n",
    "    train_loader = train_loader,\n",
    "    val_loader = val_loader,\n",
    "    test_loader = test_loader,\n",
    "    device = device,\n",
    "    normalizer = None,\n",
    "    log_writer = log_writer,\n",
    "    checkpoint_dir = save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1332)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To see the Initial Loss as a reference\n",
    "distances = []\n",
    "mae = 0\n",
    "num = 0\n",
    "c = 0\n",
    "for count, batch in enumerate(test_loader):\n",
    "    fixed_base = batch.fixed_base\n",
    "    free_atom_idx = torch.LongTensor(np.where(fixed_base.cpu() == 0)[0])\n",
    "    atom_pos = batch.atom_pos[free_atom_idx].cpu().detach()\n",
    "#     atom_pos = model(batch).cpu().detach()\n",
    "    y = batch.y.cpu().detach()\n",
    "    loss = criterion(atom_pos, y)\n",
    "    n = y.shape[0]\n",
    "    mae += loss *n\n",
    "    num += n\n",
    "    avg = mae/num\n",
    "#     distances.append(dist)\n",
    "    c+=1\n",
    "\n",
    "avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1332, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### To check if the loss function works correctly\n",
    "\n",
    "def get_mae(dataset):\n",
    "    distances = []\n",
    "    for data in dataset:\n",
    "        free_atom_idx = np.where(data.fixed_base.cpu() == 0)[0]\n",
    "        atom_pos = data.atom_pos[free_atom_idx]\n",
    "        y = data.y\n",
    "        dist = torch.sqrt(torch.sum((atom_pos-y)**2, dim=1))\n",
    "        distances.append(dist)\n",
    "    mae = torch.mean(torch.cat(distances))\n",
    "    return mae\n",
    "\n",
    "print(get_mae(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 \t MAE: 0.8139 \t time: 507.779336\n",
      "epoch: 1 \t MAE: 0.1374 \t time: 92.901018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-47797b177c13>\", line 2, in <module>\n",
      "    trainer.step(n_epoch=n_epoch)\n",
      "  File \"/home/junwoony/Desktop/baselines/preprocessing/train_positions.py\", line 54, in step\n",
      "    mae_error = self.validate(epoch).cpu().detach()\n",
      "  File \"/home/junwoony/Desktop/baselines/preprocessing/train_positions.py\", line 187, in validate\n",
      "    output = self.model(data).cpu().detach()\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 547, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/junwoony/Desktop/baselines/preprocessing/models/dogss.py\", line 150, in forward\n",
      "    grad = torch.autograd.grad(grad_E, atom_pos, retain_graph=True, create_graph=True)[0]\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/torch/autograd/__init__.py\", line 149, in grad\n",
      "    inputs, allow_unused)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 2040, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/junwoony/miniconda3/envs/schnet2/lib/python3.7/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.step(n_epoch=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0700)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = torch.load(os.path.join(save_dir, 'model_best.pth.tar'))\n",
    "model.load_state_dict(best_model['state_dict'])\n",
    "trainer.validate(0, test=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
